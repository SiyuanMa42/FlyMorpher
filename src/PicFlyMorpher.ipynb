{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86fca9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "def imshow_with_labels(images, labels, classes):\n",
    "    num_images = len(images)\n",
    "    grid_size = int(np.ceil(np.sqrt(num_images)))\n",
    "    fig, axs = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i in range(grid_size**2):\n",
    "        if i < num_images:\n",
    "            # img = to_pil_image(images[i])\n",
    "            # extract that image (need to transpose it back to 32x32x3)\n",
    "            img = images[i].numpy().transpose((1, 2, 0))\n",
    "            img = img / 2 + 0.5  # undo normalization\n",
    "            label = classes[labels[i]]\n",
    "            axs[i].imshow(img)\n",
    "            axs[i].set_title(f\"Label: {label}\")\n",
    "            axs[i].axis(\"off\")\n",
    "        else:\n",
    "            axs[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def load_data(path, batch_size, DataType):\n",
    "    Dataset = ImageFolder(path, transform=transform[DataType])  # type: ignore\n",
    "    if batch_size == 0:\n",
    "        batch_size = len(Dataset)\n",
    "    Dataloader = DataLoader(Dataset, batch_size=batch_size,\n",
    "                            shuffle=True, drop_last=True)\n",
    "    return Dataset, Dataloader\n",
    "\n",
    "\n",
    "def loadTrain(path, batch_size):\n",
    "    train_path = os.path.join(path, \"train\")\n",
    "    trainset, train_loader = load_data(train_path, batch_size, \"training\")\n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    # try again\n",
    "    print(\"Data shapes (train/test):\")\n",
    "    print(images.data.shape)\n",
    "\n",
    "    # and the range of pixel intensity values\n",
    "    print(\"\\nData value range:\")\n",
    "    print((torch.min(images.data), torch.max(images.data)))\n",
    "\n",
    "    # Show images\n",
    "    imshow_with_labels(images, labels, trainset.classes)\n",
    "\n",
    "    return train_loader, trainset.classes\n",
    "\n",
    "\n",
    "def loadTest(path, batch_size=0):\n",
    "    test_path = os.path.join(path, \"validation\")\n",
    "    testset, test_loader = load_data(test_path, batch_size, \"evaluate\")\n",
    "    return test_loader, testset.classes\n",
    "\n",
    "\n",
    "def function2trainModel(model, device, train_loader, lossFun, optimizer):\n",
    "    epochs = 10\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # initialize losses\n",
    "    trainLoss = np.zeros(epochs)\n",
    "    # devLoss   = torch.zeros(epochs)\n",
    "    trainAcc = np.zeros(epochs)\n",
    "    # devAcc    = torch.zeros(epochs)\n",
    "\n",
    "    for epochi in range(epochs):\n",
    "        # loop over training data batches\n",
    "        model.train()  # switch to train mode\n",
    "        batchLoss = []\n",
    "        batchAcc = []\n",
    "        for batch_idx, (X, y) in enumerate(train_loader):\n",
    "            # push data to GPU\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # forward pass and loss\n",
    "            yHat = model(X)\n",
    "            loss = lossFun(yHat, y)\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss and accuracy for this batch\n",
    "            batchLoss.append(loss.item())\n",
    "            batchAcc.append(torch.mean(\n",
    "                (torch.argmax(yHat, dim=1) == y).float()).item())\n",
    "            print(\n",
    "                f\"Epoch: {epochi+1}/{epochs}, Batch: {batch_idx}, {batch_idx+1}/{len(train_loader)}\")\n",
    "\n",
    "        # end of batch loop\n",
    "        # get average losses and accuracies across the batches\n",
    "        trainLoss[epochi] = np.mean(batchLoss)\n",
    "        trainAcc[epochi] = 100 * np.mean(batchAcc)\n",
    "    return trainLoss, trainAcc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95fe3091",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "def makeMorpherNet(printtoggle=False):\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    num_features = model.fc.in_features\n",
    "    \n",
    "    # fc ：Dropout → Linear\n",
    "    model.fc = nn.Sequential( # type: ignore\n",
    "        nn.Dropout(p=0.7),               # 这里放 dropout\n",
    "        nn.Linear(num_features, 3)\n",
    "    )\n",
    "    \n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "    return model, lossfun, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b53af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 5 flys, 14.7ms\n",
      "Speed: 2.2ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "from functools import wraps\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# 单例装饰器（线程安全）\n",
    "def singleton(cls):\n",
    "    instances = {}\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    @wraps(cls)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        if cls not in instances:\n",
    "            with lock:  # 加锁确保多线程安全\n",
    "                if cls not in instances:  # 双重检查锁定\n",
    "                    instances[cls] = cls(*args, **kwargs)\n",
    "        return instances[cls]\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# 应用装饰器\n",
    "@singleton\n",
    "class Detector:\n",
    "    def __init__(self, ModelPath, MorpherModelPath):\n",
    "        self.classes = [\"Ambiguous\", \"Long\", \"Short\"]\n",
    "\n",
    "        # 加载YOLOv8n\n",
    "        self.fly_detector = YOLO(ModelPath)\n",
    "\n",
    "        # 加载表情识别模型（保持不变）\n",
    "        self.model, _, _ = makeMorpherNet()\n",
    "        state_dict = torch.load(MorpherModelPath)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "\n",
    "        # 设置设备（优先使用GPU）\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def process(self, img):\n",
    "        # 使用YOLO进行果蝇检测\n",
    "        results = self.fly_detector.predict(img, conf=0.25, iou=0.6)\n",
    "\n",
    "        cropped_flies = []\n",
    "        flies_pos = []\n",
    "\n",
    "        # 解析YOLO检测结果\n",
    "        for result in results:\n",
    "            boxes = result.boxes.cpu().numpy()\n",
    "            for box in boxes:\n",
    "                try:\n",
    "                    # 获取xyxy坐标并转换为(x,y,w,h)格式\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                except Exception:\n",
    "                    continue\n",
    "                # 保证坐标在图像范围内\n",
    "                x1 = max(0, x1)\n",
    "                y1 = max(0, y1)\n",
    "                x2 = min(img.shape[1]-1, x2)\n",
    "                y2 = min(img.shape[0]-1, y2)\n",
    "                if x2 <= x1 or y2 <= y1:\n",
    "                    continue\n",
    "\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "\n",
    "                # 裁剪果蝇区域\n",
    "                cropped_fly = img[y1:y2, x1:x2]\n",
    "                if cropped_fly.size == 0:\n",
    "                    continue\n",
    "                cropped_fly = cv2.resize(cropped_fly, (224, 224))\n",
    "\n",
    "                cropped_flies.append(cropped_fly)\n",
    "                flies_pos.append((x1, y1, w, h))\n",
    "\n",
    "        # 如果没有检测到目标，直接返回原图\n",
    "        if len(cropped_flies) == 0:\n",
    "            return img\n",
    "\n",
    "        # 性状识别\n",
    "        tensor_flies = [self.transform2tensor(fly) for fly in cropped_flies]\n",
    "\n",
    "        # 计数容器\n",
    "        counts = {c: 0 for c in self.classes}\n",
    "        total = 0\n",
    "\n",
    "        for i, tensor_fly in enumerate(tensor_flies):\n",
    "            tensor_fly = tensor_fly.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                output = self.model(tensor_fly)\n",
    "\n",
    "            x, y, w, h = flies_pos[i]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 8)\n",
    "            max_idx = int(output.argmax().item())\n",
    "            label = self.classes[max_idx]\n",
    "            counts[label] += 1\n",
    "            total += 1\n",
    "\n",
    "            # 在框上方写类别\n",
    "            cv2.putText(img, label, (x, max(50, y - 50)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 4, (0, 128, 0), 8)\n",
    "\n",
    "        # 在图像左上角绘制统计信息（半透明背景）\n",
    "        lines = [f\"{k}: {counts[k]}\" for k in self.classes]\n",
    "        lines.append(f\"Total: {total}\")\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 4\n",
    "        thickness = 8\n",
    "        padding = 50\n",
    "\n",
    "        # 计算背景大小\n",
    "        text_sizes = [cv2.getTextSize(line, font, font_scale, thickness)[\n",
    "            0] for line in lines]\n",
    "        box_w = max(w for w, h in text_sizes) + padding * 2\n",
    "        box_h = sum(h + 50 for w, h in text_sizes) + padding\n",
    "\n",
    "        x0, y0 = 10, 10\n",
    "        overlay = img.copy()\n",
    "        bg_color = (0, 0, 0)  # black background\n",
    "        cv2.rectangle(overlay, (x0, y0),\n",
    "                      (x0 + box_w, y0 + box_h), bg_color, -1)\n",
    "        alpha = 0.55\n",
    "        cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0, img)\n",
    "\n",
    "        # 写文本\n",
    "        y_text = y0 + padding + text_sizes[0][1]\n",
    "        for idx, line in enumerate(lines):\n",
    "            cv2.putText(img, line, (x0 + padding, y_text), font,\n",
    "                        font_scale, (255, 255, 255), thickness)\n",
    "            y_text += text_sizes[idx][1] + 50\n",
    "\n",
    "        return img\n",
    "\n",
    "    def transform2tensor(self, data):\n",
    "        tensor_data = transform(data)\n",
    "        return tensor_data.unsqueeze(0)  # 添加batch维度\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    img = cv2.imread(\"demo.jpg\")\n",
    "\n",
    "    # 初始化检测器\n",
    "    detector = Detector(\"best.pt\", \"fly_morpher_resnet_1210_224.pth\")\n",
    "\n",
    "    process_img = detector.process(img)\n",
    "\n",
    "    cv2.imwrite(\"result.jpg\", process_img)\n",
    "    # cv2.imshow(\"result\", process_img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
